{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from prophet import Prophet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "\n",
    "import datetime\n",
    "from utils import utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.read_csv('data/daily_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76667</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-10.191667</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76668</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-13.812500</td>\n",
       "      <td>-16.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76669</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-16.162500</td>\n",
       "      <td>-18.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76670</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-9.512500</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76671</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-4.911765</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station       date  temp_max  temp_mean  temp_min  rainfall   snow\n",
       "76667   PALH0 2023-11-18      -6.7 -10.191667     -13.3     False  False\n",
       "76668   PALH0 2023-11-19     -10.6 -13.812500     -16.1     False  False\n",
       "76669   PALH0 2023-11-20     -10.6 -16.162500     -18.9     False  False\n",
       "76670   PALH0 2023-11-21      -4.4  -9.512500     -12.8     False  False\n",
       "76671   PALH0 2023-11-22      -3.9  -4.911765      -6.4      True   True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_date = str(datetime.date.today() - datetime.timedelta(days=4))\n",
    "test_date = '2023-11-16'\n",
    "daily = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pd, test_data_pd = models.train_test_split(daily_df, test_date, daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76660</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-3.529167</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76661</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-6.104167</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76662</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-4.766667</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76663</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-6.720833</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76664</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-3.370833</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station       date  temp_max  temp_mean  temp_min  rainfall   snow\n",
       "76660   PALH0 2023-11-11      -0.5  -3.529167      -7.2      True   True\n",
       "76661   PALH0 2023-11-12      -2.5  -6.104167     -10.0     False  False\n",
       "76662   PALH0 2023-11-13      -2.2  -4.766667      -6.1      True   True\n",
       "76663   PALH0 2023-11-14      -3.0  -6.720833     -10.0     False  False\n",
       "76664   PALH0 2023-11-15       2.2  -3.370833      -6.0      True   True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.775000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>28.3</td>\n",
       "      <td>25.033333</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>26.1</td>\n",
       "      <td>23.812500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>29.4</td>\n",
       "      <td>25.304167</td>\n",
       "      <td>20.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76667</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-10.191667</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76668</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-13.812500</td>\n",
       "      <td>-16.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76669</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-16.162500</td>\n",
       "      <td>-18.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76670</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-9.512500</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76671</th>\n",
       "      <td>PALH0</td>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-4.911765</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      station       date  temp_max  temp_mean  temp_min  rainfall   snow\n",
       "3646    72202 2023-11-16      27.0  23.775000      21.0      True  False\n",
       "3647    72202 2023-11-17      28.3  25.033333      23.0      True  False\n",
       "3648    72202 2023-11-18      26.1  23.812500      22.0      True  False\n",
       "3649    72202 2023-11-19      29.0  24.333333      21.0     False  False\n",
       "3650    72202 2023-11-20      29.4  25.304167      20.6     False  False\n",
       "...       ...        ...       ...        ...       ...       ...    ...\n",
       "76667   PALH0 2023-11-18      -6.7 -10.191667     -13.3     False  False\n",
       "76668   PALH0 2023-11-19     -10.6 -13.812500     -16.1     False  False\n",
       "76669   PALH0 2023-11-20     -10.6 -16.162500     -18.9     False  False\n",
       "76670   PALH0 2023-11-21      -4.4  -9.512500     -12.8     False  False\n",
       "76671   PALH0 2023-11-22      -3.9  -4.911765      -6.4      True   True\n",
       "\n",
       "[147 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First for one station "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train_data_pd.loc[train_data_pd.station == '72202']\n",
    "test_1 = test_data_pd.loc[test_data_pd.station == '72202']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.DataFrame(train_1.rename(columns={'date': 'ds', 'temp_min': 'y'}))\n",
    "test_1 = pd.DataFrame(test_1.rename(columns={'date': 'ds', 'temp_min': 'y'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station', 'ds', 'temp_max', 'temp_mean', 'y', 'rainfall', 'snow'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x7f8b43a2ed40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_regressor(name='temp_max')\n",
    "model.add_regressor(name='temp_mean')\n",
    "model.add_regressor(name='rainfall')\n",
    "model.add_regressor(name='snow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:27:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:27:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x7f8b43a2ed40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_1[['ds', 'y', 'temp_max', 'temp_mean', 'rainfall', 'snow']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=7)\n",
    "future = future.merge(test_1[['ds', 'temp_max', 'temp_mean', 'rainfall', 'snow']], on='ds') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_1 = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = (pd.DataFrame(test_1[['ds', 'y']])\n",
    "              .merge(forecast_1[['ds', 'yhat']], on='ds')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.864130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.177245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.341177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.522439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.985756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds     y       yhat\n",
       "0 2023-11-16  21.0  20.864130\n",
       "1 2023-11-17  23.0  22.177245\n",
       "2 2023-11-18  22.0  21.341177\n",
       "3 2023-11-19  21.0  20.522439\n",
       "4 2023-11-20  20.6  21.985756"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7565998817695939"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(eval.y, eval.yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.DataFrame(train_1.rename(columns={'date': 'ds', 'y': 'temp_min'})).rename(columns={'temp_mean': 'y'})\n",
    "test_1 = pd.DataFrame(test_1.rename(columns={'date': 'ds', 'y': 'temp_min'})).rename(columns={'temp_mean': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:38:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:38:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "model = Prophet()\n",
    "model.add_regressor(name='temp_max')\n",
    "model.add_regressor(name='temp_min')\n",
    "model.add_regressor(name='rainfall')\n",
    "model.add_regressor(name='snow')\n",
    "\n",
    "model.fit(train_1[['ds', 'y', 'temp_max', 'temp_min', 'rainfall', 'snow']])\n",
    "\n",
    "future = model.make_future_dataframe(periods=7)\n",
    "future = future.merge(test_1[['ds', 'temp_max', 'temp_min', 'rainfall', 'snow']], on='ds')\n",
    "forecast_1 = model.predict(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.376564034237821"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = (pd.DataFrame(test_1[['ds', 'y']])\n",
    "              .merge(forecast_1[['ds', 'yhat']], on='ds')\n",
    "              )\n",
    "\n",
    "eval.head()\n",
    "np.sqrt(mean_squared_error(eval.y, eval.yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>23.775000</td>\n",
       "      <td>23.860366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>25.033333</td>\n",
       "      <td>25.458914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>23.812500</td>\n",
       "      <td>24.021066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>24.755379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>25.304167</td>\n",
       "      <td>24.657423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds          y       yhat\n",
       "0 2023-11-16  23.775000  23.860366\n",
       "1 2023-11-17  25.033333  25.458914\n",
       "2 2023-11-18  23.812500  24.021066\n",
       "3 2023-11-19  24.333333  24.755379\n",
       "4 2023-11-20  25.304167  24.657423"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.DataFrame(train_1.rename(columns={'date': 'ds', 'y': 'temp_mean'})).rename(columns={'temp_max': 'y'})\n",
    "test_1 = pd.DataFrame(test_1.rename(columns={'date': 'ds', 'y': 'temp_mean'})).rename(columns={'temp_max': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:39:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:39:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5742560326199894"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Prophet()\n",
    "model.add_regressor(name='temp_mean')\n",
    "model.add_regressor(name='temp_min')\n",
    "model.add_regressor(name='rainfall')\n",
    "model.add_regressor(name='snow')\n",
    "\n",
    "model.fit(train_1[['ds', 'y', 'temp_mean', 'temp_min', 'rainfall', 'snow']])\n",
    "\n",
    "future = model.make_future_dataframe(periods=7)\n",
    "future = future.merge(test_1[['ds', 'temp_mean', 'temp_min', 'rainfall', 'snow']], on='ds')\n",
    "\n",
    "forecast_1 = model.predict(future)\n",
    "\n",
    "eval = (test_1\n",
    "        .merge(forecast_1[['ds', 'yhat', 'yhat_lower','yhat_upper']], on='ds')\n",
    "              )\n",
    "\n",
    "np.sqrt(mean_squared_error(eval.y, eval.yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>snow</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.775000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>27.123190</td>\n",
       "      <td>26.009474</td>\n",
       "      <td>28.065607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>28.3</td>\n",
       "      <td>25.033333</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>27.816811</td>\n",
       "      <td>26.668746</td>\n",
       "      <td>28.825116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>26.1</td>\n",
       "      <td>23.812500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>26.547128</td>\n",
       "      <td>25.420279</td>\n",
       "      <td>27.591037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28.039737</td>\n",
       "      <td>26.975185</td>\n",
       "      <td>29.071069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>29.4</td>\n",
       "      <td>25.304167</td>\n",
       "      <td>20.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.809738</td>\n",
       "      <td>28.747841</td>\n",
       "      <td>30.854994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>28.3</td>\n",
       "      <td>26.345833</td>\n",
       "      <td>24.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.033973</td>\n",
       "      <td>27.979343</td>\n",
       "      <td>30.055078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72202</td>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>28.9</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>23.3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28.419257</td>\n",
       "      <td>27.475474</td>\n",
       "      <td>29.479997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station         ds     y  temp_mean  temp_min  rainfall   snow       yhat  \\\n",
       "0   72202 2023-11-16  27.0  23.775000      21.0      True  False  27.123190   \n",
       "1   72202 2023-11-17  28.3  25.033333      23.0      True  False  27.816811   \n",
       "2   72202 2023-11-18  26.1  23.812500      22.0      True  False  26.547128   \n",
       "3   72202 2023-11-19  29.0  24.333333      21.0     False  False  28.039737   \n",
       "4   72202 2023-11-20  29.4  25.304167      20.6     False  False  29.809738   \n",
       "5   72202 2023-11-21  28.3  26.345833      24.4     False  False  29.033973   \n",
       "6   72202 2023-11-22  28.9  25.500000      23.3     False  False  28.419257   \n",
       "\n",
       "   yhat_lower  yhat_upper  \n",
       "0   26.009474   28.065607  \n",
       "1   26.668746   28.825116  \n",
       "2   25.420279   27.591037  \n",
       "3   26.975185   29.071069  \n",
       "4   28.747841   30.854994  \n",
       "5   27.979343   30.055078  \n",
       "6   27.475474   29.479997  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1 = pd.DataFrame(train_1.rename(columns={'date': 'ds', 'y': 'temp_max'})).rename(columns={'snow': 'y'})\n",
    "test_1 = pd.DataFrame(test_1.rename(columns={'date': 'ds', 'y': 'temp_max'})).rename(columns={'snow': 'y'})\n",
    "\n",
    "\n",
    "model = Prophet()\n",
    "model.add_regressor(name='temp_mean')\n",
    "model.add_regressor(name='temp_min')\n",
    "model.add_regressor(name='rainfall')\n",
    "model.add_regressor(name='temp_max')\n",
    "\n",
    "model.fit(train_1[['ds', 'y', 'temp_mean', 'temp_min', 'rainfall', 'temp_max']])\n",
    "\n",
    "future = model.make_future_dataframe(periods=7)\n",
    "future = future.merge(test_1[['ds', 'temp_mean', 'temp_min', 'rainfall', 'temp_max']], on='ds')\n",
    "forecast_1 = model.predict(future)\n",
    "eval = (test_1\n",
    "        .merge(forecast_1[['ds', 'yhat', 'yhat_lower','yhat_upper']], on='ds')\n",
    "              )\n",
    "\n",
    "np.sqrt(mean_squared_error(eval.y, eval.yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model on all stations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72202</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>26.7</td>\n",
       "      <td>25.957143</td>\n",
       "      <td>24.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72202</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>27.2</td>\n",
       "      <td>25.033333</td>\n",
       "      <td>23.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72202</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>28.3</td>\n",
       "      <td>24.620833</td>\n",
       "      <td>21.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72202</td>\n",
       "      <td>2013-11-25</td>\n",
       "      <td>25.6</td>\n",
       "      <td>23.179167</td>\n",
       "      <td>21.7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72202</td>\n",
       "      <td>2013-11-26</td>\n",
       "      <td>27.2</td>\n",
       "      <td>25.016667</td>\n",
       "      <td>22.8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station       date  temp_max  temp_mean  temp_min  rainfall   snow\n",
       "0   72202 2013-11-22      26.7  25.957143      24.4      True  False\n",
       "1   72202 2013-11-23      27.2  25.033333      23.9      True  False\n",
       "2   72202 2013-11-24      28.3  24.620833      21.7     False  False\n",
       "3   72202 2013-11-25      25.6  23.179167      21.7      True  False\n",
       "4   72202 2013-11-26      27.2  25.016667      22.8      True  False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_data_pd, columns=['station'])\n",
    "test_df = pd.get_dummies(test_data_pd, columns=['station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_df.rename(columns={'date': 'ds', 'temp_min' : 'y'}))\n",
    "test_df = pd.DataFrame(test_df.rename(columns={'date': 'ds',  'temp_min': 'y'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x7f8b41ab93c0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Prophet()\n",
    "model.add_regressor(name='temp_mean')\n",
    "model.add_regressor(name='snow')\n",
    "model.add_regressor(name='rainfall')\n",
    "model.add_regressor(name='temp_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_df.columns:\n",
    "    if 'station' in col:\n",
    "        model.add_regressor(name=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:48:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:49:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x7f8b41ab93c0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=7)\n",
    "future = future.merge(test_df.drop('y', axis=1), on='ds')\n",
    "\n",
    "forecast_1 = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = (test_df\n",
    "        .merge(forecast_1[['ds', 'yhat']], on='ds')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.80841528875813"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(eval_model.y, eval_model.yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = daily_df.station.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = dict(zip(range(len(station_ids)), station_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictor(y: str, X: list, train: pd.DataFrame, \n",
    "                    test: pd.DataFrame, stations: dict, days: int = 7):\n",
    "    \n",
    "    models = dict()\n",
    "    for i, station in stations.items():\n",
    "        train_1 = train.loc[train.station == station]\n",
    "        test_1 = test.loc[test.station == station]\n",
    "\n",
    "        train_1 = pd.DataFrame(train_1.rename(columns={'date': 'ds', y: 'y'}))\n",
    "        test_1 = pd.DataFrame(test_1.rename(columns={'date': 'ds', y: 'y'}))\n",
    "\n",
    "        models[i] = Prophet()\n",
    "        for x in X:\n",
    "            models[i].add_regressor(name=x)\n",
    "\n",
    "        models[i].fit(train_1[['ds', 'y'] + X])\n",
    "\n",
    "        future = models[i].make_future_dataframe(periods=days)\n",
    "        future = future.merge(test_1[['ds'] + X], on='ds') \n",
    "\n",
    "        forecast_1 = models[i].predict(future)\n",
    "\n",
    "        eval_m = (pd.DataFrame(test_1[['ds', 'y']])\n",
    "                    .merge(forecast_1[['ds', 'yhat']], on='ds')\n",
    "                    )\n",
    "\n",
    "        print(f\"MSE = {np.sqrt(mean_squared_error(eval_m.y, eval_m.yhat))}\")\n",
    "\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:06:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.7022818047205439\n"
     ]
    }
   ],
   "source": [
    "model_min = model_predictor('temp_min', \n",
    "                            ['temp_max', 'temp_mean', 'rainfall', 'snow'], \n",
    "                            train_data_pd, test_data_pd, stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:57:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:57:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:57:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "for i, station in stations.items():\n",
    "    train_1 = train_data_pd.loc[train_data_pd.station == station]\n",
    "    test_1 = test_data_pd.loc[test_data_pd.station == station]\n",
    "\n",
    "    train_1 = pd.DataFrame(train_1.rename(columns={'date': 'ds', 'temp_min': 'y'}))\n",
    "    test_1 = pd.DataFrame(test_1.rename(columns={'date': 'ds', 'temp_min': 'y'}))\n",
    "\n",
    "    models_min[i] = Prophet()\n",
    "    models_min[i].add_regressor(name='temp_max')\n",
    "    models_min[i].add_regressor(name='temp_mean')\n",
    "    models_min[i].add_regressor(name='rainfall')\n",
    "    models_min[i].add_regressor(name='snow')\n",
    "\n",
    "    models_min[i].fit(train_1[['ds', 'y', 'temp_max', 'temp_mean', 'rainfall', 'snow']])\n",
    "\n",
    "    future = models_min[i].make_future_dataframe(periods=7)\n",
    "    future = future.merge(test_1[['ds', 'temp_max', 'temp_mean', 'rainfall', 'snow']], on='ds') \n",
    "\n",
    "    forecast_1 = models_min[i].predict(future)\n",
    "\n",
    "    eval_m = (pd.DataFrame(test_1[['ds', 'y']])\n",
    "                .merge(forecast_1[['ds', 'yhat']], on='ds')\n",
    "                )\n",
    "                        \n",
    "    models_min[station] = np.sqrt(mean_squared_error(eval_m.y, eval_m.yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_features(df, label=None):\n",
    "    \"\"\"\n",
    "    Creates time series features\n",
    "    \"\"\"\n",
    "\n",
    "    if not daily_df.date.dtype == 'datetime64[ns]' :\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    \n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    \n",
    "    X = df[['month','year',\n",
    "           'dayofyear','dayofmonth']]\n",
    "    if label:\n",
    "        y = df[label]\n",
    "        X = df.drop(label, axis=1)\n",
    "        return X, y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data = xgb_features(daily_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data  = xgb_data.sort_values(by='date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data['station'] = pd.Categorical(xgb_data['station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_configs(d):\n",
    "    for vcomb in itertools.product(*d.values()):\n",
    "        yield dict(zip(d.keys(), vcomb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station', 'temp_max', 'temp_mean', 'rainfall', 'snow', 'month', 'year',\n",
       "       'dayofyear', 'dayofmonth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_data.drop([y,'date'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data = pd.get_dummies(xgb_data, columns=['station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 2, 'n_estimators': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 2, 'n_estimators': 700}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 2, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 4, 'n_estimators': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 4, 'n_estimators': 700}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 4, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 6, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 6, 'n_estimators': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 6, 'n_estimators': 700}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 6, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 8, 'n_estimators': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 8, 'n_estimators': 700}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 8, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n"
     ]
    }
   ],
   "source": [
    "tss = TimeSeriesSplit(n_splits=3, test_size=4)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': np.arange(2, 10, 2),\n",
    "    'n_estimators': np.arange(100, 1200, 300),\n",
    "}\n",
    "\n",
    "params =  {'learning_rate': 0.1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': 4,\n",
    "    # 'enable_categorical': True,\n",
    "    'random_state': 42}\n",
    "\n",
    "fold = 0\n",
    "# preds = []\n",
    "scores = []\n",
    "y = \"temp_min\"\n",
    "xgb_data.dropna(inplace=True)\n",
    "features = xgb_data.drop([y,'date'], axis=1).columns\n",
    "grid = dict_configs(param_grid)\n",
    "for train_idx, val_idx in tss.split(xgb_data):\n",
    "    train = xgb_data.iloc[train_idx]\n",
    "    test = xgb_data.iloc[val_idx]\n",
    "    cv_results = dict()\n",
    "    for cv_params in grid:\n",
    "        X_train = train[features]\n",
    "        y_train = train[y].shift(1).dropna()\n",
    "\n",
    "        X_train.drop(index=X_train.index[:1], axis=0, inplace=True)\n",
    "\n",
    "        X_test = test[features]\n",
    "        y_test = test[y]\n",
    "\n",
    "        params.update(cv_params)\n",
    "        print(params)\n",
    "        # reg = MultiOutputRegressor(xgb.XGBRegressor(**params))\n",
    "        reg = xgb.XGBRegressor(**params)\n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                verbose=0)\n",
    "\n",
    "        y_pred = reg.predict(X_test)\n",
    "#       preds.append(y_pred)\n",
    "        cv_results[str(cv_params)] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        scores.append(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412},\n",
       " {\"{'max_depth': 2, 'n_estimators': 100}\": 5.742300992609579,\n",
       "  \"{'max_depth': 2, 'n_estimators': 400}\": 5.8441100751865855,\n",
       "  \"{'max_depth': 2, 'n_estimators': 700}\": 5.952860256466153,\n",
       "  \"{'max_depth': 2, 'n_estimators': 1000}\": 6.006600847203467,\n",
       "  \"{'max_depth': 4, 'n_estimators': 100}\": 5.533827505887801,\n",
       "  \"{'max_depth': 4, 'n_estimators': 400}\": 6.708383722512493,\n",
       "  \"{'max_depth': 4, 'n_estimators': 700}\": 6.541898164130732,\n",
       "  \"{'max_depth': 4, 'n_estimators': 1000}\": 7.425928657166456,\n",
       "  \"{'max_depth': 6, 'n_estimators': 100}\": 6.032389297751595,\n",
       "  \"{'max_depth': 6, 'n_estimators': 400}\": 5.901004638846375,\n",
       "  \"{'max_depth': 6, 'n_estimators': 700}\": 6.236974064477442,\n",
       "  \"{'max_depth': 6, 'n_estimators': 1000}\": 6.657361783456716,\n",
       "  \"{'max_depth': 8, 'n_estimators': 100}\": 6.926409826153647,\n",
       "  \"{'max_depth': 8, 'n_estimators': 400}\": 6.665698654660439,\n",
       "  \"{'max_depth': 8, 'n_estimators': 700}\": 7.325206339724756,\n",
       "  \"{'max_depth': 8, 'n_estimators': 1000}\": 7.298569744355412}]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36490</th>\n",
       "      <td>14.4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43796</th>\n",
       "      <td>1.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29224</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51102</th>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25571</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32876</th>\n",
       "      <td>7.6</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>1.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>12.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43795</th>\n",
       "      <td>6.7</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18264</th>\n",
       "      <td>0.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76649 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       day1  day2  day3  day4\n",
       "36490  14.4   8.9   3.3  24.4\n",
       "43796   1.1  14.4   8.9   3.3\n",
       "29224  -1.7   1.1  14.4   8.9\n",
       "51102   1.1  -1.7   1.1  14.4\n",
       "25571   2.8   1.1  -1.7   1.1\n",
       "...     ...   ...   ...   ...\n",
       "32876   7.6  -2.0   7.1  23.3\n",
       "10958   1.1   7.6  -2.0   7.1\n",
       "7305   12.3   1.1   7.6  -2.0\n",
       "43795   6.7  12.3   1.1   7.6\n",
       "18264   0.3   6.7  12.3   1.1\n",
       "\n",
       "[76649 rows x 4 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_frame().assign(\n",
    "    day1 = y_train.shift(1),\n",
    "    day2 = y_train.shift(2),\n",
    "    day3= y_train.shift(3),\n",
    "    day4 = y_train.shift(4)\n",
    ").drop(y, axis=1).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'objective': 'reg:squarederror', 'booster': 'gbtree', 'n_jobs': 4, 'random_state': 42, 'max_depth': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[15:11:21] /home/conda/feedstock_root/build_artifacts/xgboost-split_1700181168148/work/src/data/data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (4 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(+0xb6361) [0x7f8b52ab6361]\n  [bt] (1) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(xgboost::MetaInfo::SetInfoFromHost(xgboost::GenericParameter const&, xgboost::StringView, xgboost::Json)+0x2ac2) [0x7f8b52bb32c2]\n  [bt] (2) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(xgboost::MetaInfo::SetInfo(xgboost::GenericParameter const&, xgboost::StringView, xgboost::StringView)+0x80) [0x7f8b52bb3490]\n  [bt] (3) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xec) [0x7f8b52ab8f4c]\n  [bt] (4) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f8be2e36a4a]\n  [bt] (5) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f8be2e35fea]\n  [bt] (6) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12461) [0x7f8be2e75461]\n  [bt] (7) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x86eb) [0x7f8be2e6b6eb]\n  [bt] (8) /home/marc/miniconda3/envs/604Final/bin/python(_PyObject_MakeTpCall+0x26b) [0x55ece29cc9db]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[251], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[39m# reg = MultiOutputRegressor(xgb.XGBRegressor(**params))\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         reg \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> 47\u001b[0m         reg\u001b[39m.\u001b[39;49mfit(X_train, y_train,\n\u001b[1;32m     48\u001b[0m                 eval_set\u001b[39m=\u001b[39;49m[(X_train, y_train), (X_test, y_test)],\n\u001b[1;32m     49\u001b[0m                 verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     51\u001b[0m         y_pred \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     52\u001b[0m \u001b[39m#       preds.append(y_pred)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/sklearn.py:988\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[1;32m    987\u001b[0m     evals_result: TrainingCallback\u001b[39m.\u001b[39mEvalsLog \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 988\u001b[0m     train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m    989\u001b[0m         missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m    990\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    991\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    992\u001b[0m         group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    993\u001b[0m         qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    994\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    995\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    996\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    997\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m    998\u001b[0m         sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m    999\u001b[0m         base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1000\u001b[0m         eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1001\u001b[0m         eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1002\u001b[0m         create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1003\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1004\u001b[0m         feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1005\u001b[0m     )\n\u001b[1;32m   1006\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1008\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    429\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    430\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    445\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    446\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    449\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    450\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    451\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    452\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    453\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    454\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    455\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    456\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    457\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    458\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    459\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    462\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    464\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/core.py:754\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n\u001b[0;32m--> 754\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_info(\n\u001b[1;32m    755\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m    756\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m    757\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    758\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    759\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    760\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[1;32m    761\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[1;32m    762\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    763\u001b[0m )\n\u001b[1;32m    765\u001b[0m \u001b[39mif\u001b[39;00m feature_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39m=\u001b[39m feature_names\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/core.py:819\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[0;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m    818\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 819\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_label(label)\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_weight(weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/core.py:950\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \n\u001b[1;32m    944\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[39m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m--> 950\u001b[0m dispatch_meta_backend(\u001b[39mself\u001b[39;49m, label, \u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/data.py:1134\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[0;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_series(data):\n\u001b[0;32m-> 1134\u001b[0m     _meta_from_pandas_series(data, name, dtype, handle)\n\u001b[1;32m   1135\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39mif\u001b[39;00m _is_dlpack(data):\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/data.py:443\u001b[0m, in \u001b[0;36m_meta_from_pandas_series\u001b[0;34m(data, name, dtype, handle)\u001b[0m\n\u001b[1;32m    441\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto_dense()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 443\u001b[0m _meta_from_numpy(data, name, dtype, handle)\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/data.py:1050\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[0;34m(data, field, dtype, handle)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMasked array is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1049\u001b[0m interface_str \u001b[39m=\u001b[39m _array_interface(data)\n\u001b[0;32m-> 1050\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "File \u001b[0;32m~/miniconda3/envs/604Final/lib/python3.10/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [15:11:21] /home/conda/feedstock_root/build_artifacts/xgboost-split_1700181168148/work/src/data/data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (4 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(+0xb6361) [0x7f8b52ab6361]\n  [bt] (1) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(xgboost::MetaInfo::SetInfoFromHost(xgboost::GenericParameter const&, xgboost::StringView, xgboost::Json)+0x2ac2) [0x7f8b52bb32c2]\n  [bt] (2) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(xgboost::MetaInfo::SetInfo(xgboost::GenericParameter const&, xgboost::StringView, xgboost::StringView)+0x80) [0x7f8b52bb3490]\n  [bt] (3) /home/marc/miniconda3/envs/604Final/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xec) [0x7f8b52ab8f4c]\n  [bt] (4) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/../../libffi.so.8(+0x6a4a) [0x7f8be2e36a4a]\n  [bt] (5) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/../../libffi.so.8(+0x5fea) [0x7f8be2e35fea]\n  [bt] (6) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12461) [0x7f8be2e75461]\n  [bt] (7) /home/marc/miniconda3/envs/604Final/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x86eb) [0x7f8be2e6b6eb]\n  [bt] (8) /home/marc/miniconda3/envs/604Final/bin/python(_PyObject_MakeTpCall+0x26b) [0x55ece29cc9db]\n\n"
     ]
    }
   ],
   "source": [
    "tss = TimeSeriesSplit(n_splits=3, test_size=4)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': np.arange(2, 10, 2),\n",
    "    'n_estimators': np.arange(100, 1200, 300),\n",
    "}\n",
    "\n",
    "params =  {'learning_rate': 0.1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': 4,\n",
    "    # 'enable_categorical': True,\n",
    "    'random_state': 42}\n",
    "\n",
    "fold = 0\n",
    "# preds = []\n",
    "scores = []\n",
    "y = \"temp_min\"\n",
    "xgb_data.dropna(inplace=True)\n",
    "features = xgb_data.drop([y,'date'], axis=1).columns\n",
    "grid = dict_configs(param_grid)\n",
    "for train_idx, val_idx in tss.split(xgb_data):\n",
    "    train = xgb_data.iloc[train_idx]\n",
    "    test = xgb_data.iloc[val_idx]\n",
    "    cv_results = dict()\n",
    "    for cv_params in grid:\n",
    "        X_train = train[features]\n",
    "        y_train = train[y]\n",
    "\n",
    "        y_train.to_frame().assign(\n",
    "                day1 = y_train.shift(1),\n",
    "                day2 = y_train.shift(2),\n",
    "                day3= y_train.shift(3),\n",
    "                day4 = y_train.shift(4)\n",
    "            ).drop(y, axis=1).dropna()\n",
    "        \n",
    "        X_train.drop(index=X_train.index[:4], axis=0, inplace=True)\n",
    "\n",
    "        X_test = test[features]\n",
    "        y_test = test[y]\n",
    "        y_test = y_test.to_numpy().reshape(-1, 4)\n",
    "\n",
    "        params.update(cv_params)\n",
    "        print(params)\n",
    "        reg = xgb.XGBRegressor(**params)\n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                verbose=0)\n",
    "\n",
    "        y_pred = reg.predict(X_test)\n",
    "#       preds.append(y_pred)\n",
    "        cv_results[str(cv_params)] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        scores.append(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificaition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=3, test_size=4)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': np.arange(2, 10, 2),\n",
    "    'n_estimators': np.arange(100, 1200, 300),\n",
    "}\n",
    "\n",
    "params =  {'learning_rate': 0.1,\n",
    "    'objective': 'reg:logistic',\n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': 4,\n",
    "    # 'enable_categorical': True,\n",
    "    'random_state': 42}\n",
    "\n",
    "fold = 0\n",
    "# preds = []\n",
    "scores = []\n",
    "y = \"snow\"\n",
    "xgb_data.dropna(inplace=True)\n",
    "features = xgb_data.drop([y,'date'], axis=1).columns\n",
    "grid = dict_configs(param_grid)\n",
    "for train_idx, val_idx in tss.split(xgb_data):\n",
    "    train = xgb_data.iloc[train_idx]\n",
    "    test = xgb_data.iloc[val_idx]\n",
    "    cv_results = dict()\n",
    "    for cv_params in grid:\n",
    "        X_train = train[features]\n",
    "        y_train = train[y].shift(1).dropna()\n",
    "\n",
    "        X_train.drop(index=X_train.index[:1], axis=0, inplace=True)\n",
    "\n",
    "        X_test = test[features]\n",
    "        y_test = test[y]\n",
    "\n",
    "        params.update(cv_params)\n",
    "        print(params)\n",
    "        # reg = MultiOutputRegressor(xgb.XGBRegressor(**params))\n",
    "        reg = xgb.XGBRegressor(**params)\n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                verbose=0)\n",
    "\n",
    "        y_pred = reg.predict(X_test)\n",
    "#       preds.append(y_pred)\n",
    "        cv_results[str(cv_params)] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        scores.append(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Lagged Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data[\"temp_mean\"].ewm(alpha=.9, adjust=False).mean().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Restrict Months\n",
    "#### only include months November and December "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "604Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
